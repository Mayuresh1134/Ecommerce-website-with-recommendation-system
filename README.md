# We are doing this for our ROSPL project

## E-Commerce Product Placement Optimization using Apriori Algorithm

### Project Overview:
This project aims to enhance product placement and recommendations on e-commerce platforms by leveraging association rule mining, specifically through the Apriori algorithm. By analyzing transactional data, we identify frequent itemsets and generate association rules to discover valuable patterns in customer buying behavior. These insights can be used to optimize product placement, improve customer experience, and drive sales growth.

The scope of the project is focused on the data-driven aspect of e-commerce optimization, without extending to website design or broader marketing strategies. Our work provides a framework for analyzing transactional data and making informed decisions on how to organize and recommend products to users. It also contains an admin login section with an additional sale predictor section. This section predicts the sale of an item given some characteristics of it as an input.

### Features:
- **Optimized Product Placement**: By understanding which products are frequently bought together, businesses can strategically place these products near each other to increase cross-sell opportunities.
- **Improved Recommendations**: The association rules derived from the transactional data can be used to recommend products to customers, improving their overall shopping experience.
- **Scalability and Actionability**: The Apriori algorithm helps in handling large-scale transactional data and provides actionable insights for businesses to implement data-driven improvements.

### The Apriori Algorithm:
The Apriori algorithm, introduced by Agrawal et al. in 1994, is a classic technique for association rule mining. It identifies frequent itemsets in large transactional databases and generates association rules that provide insights into customer buying patterns.

#### How Apriori Works:
1. **Frequent Itemset Generation**: 
   - The algorithm first generates frequent itemsets, where an itemset is considered frequent if it occurs in the dataset with a frequency greater than a predefined threshold (support). 
   - This is done through an iterative process:
     - In the first pass, itemsets of size 1 (individual items) are analyzed to find frequent itemsets.
     - In subsequent passes, larger itemsets (e.g., pairs, triples) are generated by combining smaller frequent itemsets.
     - This process continues until no further frequent itemsets can be found.

2. **Association Rule Generation**: 
   - Once frequent itemsets are identified, the algorithm generates association rules based on support and confidence:
     - **Support**: The proportion of transactions in which the itemset appears.
     - **Confidence**: The likelihood of item B being purchased when item A is already in the transaction.
   - For example, if "bread" and "butter" frequently appear together in transactions, an association rule like "if bread is purchased, butter is also purchased" can be generated.

### Key Features of Apriori:
- **Breadth-First Search (BFS)**: The algorithm employs BFS to systematically explore itemsets.
- **Pruning**: Apriori prunes itemsets that do not meet the minimum support threshold, improving efficiency.
- **Challenges**: The algorithm may face scalability issues as the number of items grows, but its outputs are easy to interpret and provide clear insights into product relationships.

### Dataset:
We have used the UCI Machine Learning Repository's Online Retail dataset. [Link to dataset](https://archive.ics.uci.edu/dataset/352/online+retail).  
It is a transnational data set that contains all the transactions occurring between 01/12/2010 and 09/12/2011 for a UK-based and registered non-store online retail.  
It has roughly 500,000 rows and 6 features.

### Installation Guide:
To download and run this project on your system:

1. Clone this repository using the git command:
   ```bash
   git clone <repository's URL>
2. Open the cloned folder in VS Code or any other IDE.
3. In the app.py file, change the paths of the scaler and model with your scaler and model's paths.
4. Run app.py.
5. To log in as admin and access the sale predictor, use the credentials given in the cred.txt file.
